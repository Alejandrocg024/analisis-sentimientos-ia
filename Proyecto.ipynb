{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter SensIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar este proyecto haremos uso de los siguientes paquetes de Python:\n",
    "* _[_NLTK_](http://pandas.pydata.org/)_: herramienta para el análisis de datos. Lo usaremos a la hora de \"limpiar\" el texto.\n",
    "* _[_Re_](https://docs.python.org/es/3/library/re.html)_: operaciones con expresiones regulares. Lo usaremos a la hora de \"limpiar\" el texto.\n",
    "* _[_TextBlob_](https://textblob.readthedocs.io/en/dev/)_: herramienta para procesar datos de texto. Lo usaremos para el etiquetado del texto.\n",
    "* _[_CSV_](https://docs.python.org/3/library/csv.html)_: herramienta para leer y escribir csv. Lo usaremos para tratar con csv, ya que tenemos familiaridad con éste.\n",
    "* _[_Pandas_](http://pandas.pydata.org/)_: herramienta para el análisis de datos. Lo usaremos también para trabajar con CSV.\n",
    "* _[_scikit-learn_](http://scikit-learn.org)_: herramienta que proporcioa un marco de trabajo para el aprendizaje automático. Lo usaremos para trabajar con nuesto modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los paquetes _NLTK_ y _TextBlob_ han de ser instalados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, importamos todos los paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Apartado 2: Eliminar palabras que no aportan información\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#Descargamos las ultimas versiones para que funcione correctamente\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Apartado 3: Etiquetado de datos\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Apartado 4\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Apartado 5\n",
    "#Apartado 6\n",
    "#Apartado 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 1. Recopilación de datos\n",
    "\n",
    "Hemos recopilado 50.000 tweets que pueden tener un sentimiento positivo, negativo o neutro. Los hemos obtenido a través de [_Kaggle_](https://www.kaggle.com/datasets/kazanova/sentiment140) y los hemos almacenado en el fichero DatosRecopilados.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 2. Limpieza de texto\n",
    "\n",
    "Creamos una función _limpiar_texto_ que, a partir de un tweet original, obtiene un texto limpio sin stop words, menciones, hastags, URLs y cualquier otro simbolo extraño utilizando técnicas de lematización y tokenización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    # Eliminamos elementos que no nos sirven\n",
    "    texto = re.sub(r'http\\S+', \"\", texto)  # eliminamos URLs\n",
    "    texto = re.sub(r'#\\w+', \"\", texto)  # eliminamos hashtags\n",
    "    texto = re.sub(r'@\\w+', \"\", texto)  # eliminamos menciones\n",
    "    texto = re.sub(r'[^\\w\\s]', \"\", texto)  # eliminamos otros símbolos extraños\n",
    "    \n",
    "    # Convertimos el texto a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(texto)\n",
    "    \n",
    "    # Eliminamos stop words y lematizamos\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    palabras_limpias = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Palabras limpias a una sola cadena de texto\n",
    "    texto_limpio = ' '.join(palabras_limpias)\n",
    "    \n",
    "    return texto_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 3. Etiquetado de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que sirva para poder etiquetar el texto que hemos limpiado previamente utilizando la libreria _TextBlob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar(texto):\n",
    "    # Creamos un objeto TextBlob con el texto a analizar\n",
    "    blob = TextBlob(texto)\n",
    "    # Valor del análisis de sentimiento\n",
    "    sentimiento = blob.sentiment.polarity\n",
    "    # En función del análisis de sentimiento, etiquetamos\n",
    "    if sentimiento >= 0.7:\n",
    "        etiqueta = \"Muy feliz\"\n",
    "    elif sentimiento >= 0.2:\n",
    "        etiqueta = \"Contento\"\n",
    "    elif sentimiento >= -0.2:\n",
    "        etiqueta = \"Neutro\"\n",
    "    elif sentimiento >= -0.7:\n",
    "        etiqueta = \"Molesto\"\n",
    "    else:\n",
    "        etiqueta = \"Hater\"\n",
    "    return etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También crearemos una función a la que le introduces el nombre del archivo csv que tenga los datos recopilados y limpios y etiqueta cada linea con su sentimiento correspondiente. La función creará un csv con el nombre indicado que contiene dos columnas nuevas, una para cada texto limpio y otra para la etiqueta correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetado_datos(input_file, output_file):\n",
    "    #Leemos los datos delimitados por ;\n",
    "    reader = pandas.read_csv(input_file, delimiter=\";\")\n",
    "    #Añadimos las 2 nuevas columnas\n",
    "    reader[\"Texto limpio\"] = \"\"\n",
    "    reader[\"Etiquetado\"] = \"\"\n",
    "    for i, row in reader.iterrows():\n",
    "        # Usamos la columna en la cuál está el texto en bruto\n",
    "        valor_columna = row[1]  \n",
    "        # Limpiamos el texto para que pueda ser analizado\n",
    "        texto_limpio = limpiar_texto(valor_columna)\n",
    "        # Lo etiquetamos\n",
    "        texto_etiquetado = etiquetar(texto_limpio)\n",
    "        # Añadimos los nuevos valores a las correspondientes filas\n",
    "        reader.at[i, \"Texto limpio\"] = texto_limpio\n",
    "        reader.at[i, \"Etiquetado\"] = texto_etiquetado\n",
    "\n",
    "    # Guardamos los cambios en un nuevo archivo csv\n",
    "    reader.to_csv(output_file, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Añadir datos al csv\n",
    "\n",
    "A continuación, procesaremos todos los datos de prueba almcenados en \"DatosRecopilados.csv\" con las dos funciones realizadas y los almacenaremos en un archivo CSV llamado \"DatosFinales.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetado_datos('DatosRecopilados.csv', 'DatosFinales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 4. Validación de la predicción realizada.\n",
    "\n",
    "A partir del csv generado en el apartado anterior \"DatosFinales.csv\" hemos creado el siguiente csv llamado \"DatosFinalesRevisados.csv\". Así, hemos creado un conjunto de datos etiquetados por un modelo ya existente y corregidos por un humano que usaremos como datos de entrenamiento y prueba en el desarrollo del modelo\n",
    "\n",
    "Por tanto, leemos nuestro csv corregido con las distintas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDatos = pandas.read_csv('DatosFinalesRevisados.csv', delimiter=';',encoding = 'utf-8', header=0,\n",
    "                       names=['id', 'mensaje', 'texto_limpio','valor_propuesto'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccion de atributos y objetivos\n",
    "\n",
    "A continuación, seleccionamos los atributos y objetivos de nuestro modelo para, posteriormente codificarlos con las herramientas adecuadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributo = csvDatos['texto_limpio'].values.astype('U')   # selección de las columnas de atributos\n",
    "objetivo = csvDatos['valor_propuesto']  # selección de la columna objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos CountVectorizer para codificar el texto debido a que es el mejor \n",
    "# codificador a la hora de usar cadenas de texto puesto que no son etiquetas ni números\n",
    "codificador_atributo = CountVectorizer()\n",
    "\n",
    "# Para codificar el objetivo usamos LabelEncoder debido a que solo puede tomar\n",
    "# 5 valores, es decir, etiquetas\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "\n",
    "atributo_codificado = codificador_atributo.fit_transform(atributo)\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el porcentaje de entradas que tienen las distintas etiquetas\n",
    "print(pandas.Series(objetivo).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 5. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributo_entrenamiento, atributo_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributo_codificado, objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria, para que el muestreo sea reproducible,\n",
    "        # a pesar de ser aleatorio\n",
    "        random_state=12345,\n",
    "        # Tamaño del conjunto de prueba\n",
    "        test_size=.33,\n",
    "        # Estratificamos respecto a la distribución de valores en la variable objetivo\n",
    "        stratify=objetivo_codificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que el conjunto de prueba contiene el 33 % de los datos, en la misma proporción\n",
    "# con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de pruebas requeridos:', 50000 * .33)\n",
    "print('Filas del array de atributos de prueba:', atributo_prueba.shape[0])\n",
    "print('Longitud del vector de objetivos de prueba:', len(objetivo_prueba))\n",
    "print('Proporción de clases en el vector de objetivos de prueba:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_prueba)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que el conjunto de entrenamiento contiene el resto de los datos, en la misma\n",
    "# proporción con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de entrenamiento requeridos:', 50000 * .67)\n",
    "print('Filas del array de atributos de entrenamiento:', atributo_entrenamiento.shape[0])\n",
    "print('Longitud del vector de objetivos de entrenamiento:', len(objetivo_entrenamiento))\n",
    "print('Proporción de clases en el vector de objetivos de entrenamiento:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_entrenamiento)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_ejemplos = pandas.DataFrame([['im really sick fever'],\n",
    "                                    ['im happy family friends']], columns=['texto_limpio'])\n",
    "nuevos_ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_NB = naive_bayes.MultinomialNB(alpha=0.5)\n",
    "clasif_NB.fit(atributo_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasif_NB.predict(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))\n",
    "codificador_objetivo.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_NB.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_CART = tree.DecisionTreeClassifier(\n",
    "    max_depth=10,  # máxima profundidad del árbol\n",
    "    random_state=54321  # semilla aleatoria, para que el código sea reproducible\n",
    ")\n",
    "clasif_CART.fit(atributo_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(50, 20))  # Anchura y altura del gráfico\n",
    "árbol = tree.plot_tree(clasif_CART,\n",
    "                       feature_names=codificador_atributo.get_feature_names_out(),\n",
    "                       class_names=codificador_objetivo.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasif_CART.predict(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))\n",
    "codificador_objetivo.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_CART.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN = neighbors.KNeighborsClassifier(\n",
    "    n_neighbors=5,  # Número de vecinos a considerar\n",
    "    metric='euclidean'  # Distancia euclídea como métrica\n",
    ")\n",
    "clasif_kNN.fit(atributo_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancias, vecinos = clasif_kNN.kneighbors(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecinos más cercanos y distancia a ellos\n",
    "print(\"Ejemplo número 1:\")\n",
    "print(nuevos_ejemplos.iloc[[0]])\n",
    "print()\n",
    "print(\"5 vecinos más cercanos:\")\n",
    "print(pandas.DataFrame(codificador_atributo.inverse_transform(atributo_entrenamiento[vecinos[0]]),\n",
    "                       index=vecinos[0]).assign(\n",
    "    distancia=distancias[0],\n",
    "    clase=codificador_objetivo.inverse_transform(objetivo_entrenamiento[vecinos[0]])\n",
    "))\n",
    "\n",
    "print(\"\\n\\nEjemplo número 2:\")\n",
    "print(nuevos_ejemplos.iloc[[1]])\n",
    "print()\n",
    "print(\"5 vecinos más cercanos:\")\n",
    "print(pandas.DataFrame(codificador_atributo.inverse_transform(atributo_entrenamiento[vecinos[1]]),\n",
    "                       index=vecinos[1]).assign(\n",
    "    distancia=distancias[1],\n",
    "    clase=codificador_objetivo.inverse_transform(objetivo_entrenamiento[vecinos[1]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasif_kNN.predict(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))\n",
    "codificador_objetivo.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada de los métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes\n",
    "#creo un diccionario vacio\n",
    "cv_scores_NB = {}\n",
    "for k in range(3, 21, 1):\n",
    "    k /= 10.0    #creo una instancia de modelo Naives Bayes para cada valor de suavizado (0.3-2.0)\n",
    "    clasif_NB = naive_bayes.MultinomialNB(alpha=k)\n",
    "    #guardo en cv_scores el resultado de cross_val_score que va hacer una validacion cruzada para cada suavizado\n",
    "    cv_scores = model_selection.cross_val_score(clasif_NB,\n",
    "                                                atributo_entrenamiento,\n",
    "                                                objetivo_entrenamiento,\n",
    "                                                #Número de pliegues en los que se dividen los datos para realizar la validación\n",
    "                                                cv=10)\n",
    "    #lo guardo en el diccionario clave=suavizado, valor=media del resultado de la validacion cruzada para ese suavizado.\n",
    "    cv_scores_NB[k] = cv_scores.mean()\n",
    "\n",
    "# Muestro todas las puntuaciones\n",
    "print(cv_scores_NB)\n",
    "# Devuelvo el suavizado que obtiene una mejor puntuación\n",
    "mejor_k_NB = max(cv_scores_NB, key=cv_scores_NB.get)\n",
    "print(f'Mejor suavizado: {mejor_k_NB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las 2 siguientes la estructura es la misma, por lo tanto no habrá comentarios\n",
    "explicando qué hace cada paso, sólo se mencionará aquello que sea distinto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en vez de hacerlo variando el suavizado, variamos la profundidad del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arboles de decisión\n",
    "#Tarda más tiempo\n",
    "cv_scores_CART = {}\n",
    "for p in range(1,11):\n",
    "    clasif_CART = tree.DecisionTreeClassifier(max_depth=p)\n",
    "    cv_scores = model_selection.cross_val_score(clasif_CART,\n",
    "                                                atributo_entrenamiento,\n",
    "                                                objetivo_entrenamiento,\n",
    "                                                cv=10)\n",
    "    cv_scores_CART[p] = cv_scores.mean()\n",
    "print(cv_scores_CART)\n",
    "mejor_p_CART = max(cv_scores_CART, key=cv_scores_CART.get)\n",
    "print(f'Mejor profundidad: {mejor_p_CART}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora variamos el número de vecinos que toma como referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN\n",
    "cv_scores_kNN = {}\n",
    "for k in range(1,11):\n",
    "    clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=k, metric='euclidean') \n",
    "    cv_scores = model_selection.cross_val_score(clasif_kNN,\n",
    "                                                atributo_entrenamiento,\n",
    "                                                objetivo_entrenamiento,\n",
    "                                                cv=10)\n",
    "    cv_scores_kNN[k] = cv_scores.mean()\n",
    "print(cv_scores_kNN)\n",
    "mejor_k_kNN = max(cv_scores_kNN, key=cv_scores_kNN.get)\n",
    "print(f'Mejor número de vecinos: {mejor_k_kNN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 6. Predicción de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=mejor_k_kNN, metric='euclidean')\n",
    "clasif_kNN.fit(atributo_entrenamiento, objetivo_entrenamiento)\n",
    "clasif_kNN.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El acierto es del 67%. Es menor a lo que esperábamos, ya que hemos entrenado el modelo creemos que de la manera correcta con un conjunto de datos de 50.000 entradas. Sin embargo, creemos que uno de los principales factores por lo que no hemos alcanzado un mayor porcentaje es la infinidad de tweets distintos, es decir, la dificultad de que el texto limpio de 2 tweets coincidan. Esto nos ha llevado a que a la hora de calcular con TextBlob una entrada, el resultado no coincida con lo que los modelos basados en las demás entradas nos ofrecen. Una vez obtenido este resultado hemos intentado realizar cambios que podrían mejorar el porcentaje pero no hemos sido capaces de aumentar considerablemente el número sin que aumente exponencialmente el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 7. Análisis de tweets de personajes públicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomaremos como Hater al usuario @kirawontmiss que es un personaje público con más de 1 millón de seguidores que suele criticar noticias actuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajes_negativos = pandas.DataFrame([\n",
    "['i have a really bad feeling they’re gonna cast tom holland as link'],\n",
    "['please stop vaping we can’t see shit'],\n",
    "['why the FUCK are we even still paying bills?? the world is literally ending'],\n",
    "['YEAH THIS IS GETTING SO BAD.. WHAT THE FUCK DO U MEAN HAZARDOUS ??'],\n",
    "['LMFAOOO pixar deleted the tweet'],\n",
    "['yeah society is FINISHED.. mfs are really comparing wildfires'],\n",
    "['this gotta be the worst time to post this tweet LMAOO https://twitter.com/pixar/status/1666520608107298817'],\n",
    "['who the fuck owns Kick they are out here giving out NBA contracts'],\n",
    "['i had no problem with eminem until this horrible video dropped'],\n",
    "['SO THIS WASNT A JOKE???'],\n",
    "['FINALLY WE ARE FREE'],\n",
    "['nothing could’ve prepared me for the ending'],\n",
    "['why the fuck don’t they jump over moving cars like this'],\n",
    "['LMAOO bro had the entire theater laughing'],\n",
    "['usually people hate when someone does this im surprised he got everyone laughing 😭'],\n",
    "['do you know how unlucky you have to be for some shit like this to happen to you LMAOO'],\n",
    "['for $3499 that shit better let me see into the future wtf'],\n",
    "['why she dressed like a condom before you put it on LMAOOO'],\n",
    "['LMFAOOOOOO boruto didn’t influence shit'],\n",
    "['world war 2 is over.. y’all don’t have to eat like this anymore'],\n",
    "['he’s useless as fuck'],\n",
    "['WHAT THE FUCKKK THIS SHlT IS A MASTERPIECE'],\n",
    "['the way drake said embarrassing is exactly how i expected him to say it'],\n",
    "['why are you holding the drinks like this'],\n",
    "['Ai is gonna have y’all fucked up'],\n",
    "['IM NOT MAKING IT'],\n",
    "['alright its been 7 years who the fuck was behind those clowns costumes back in 2016'],\n",
    "['this is easily the worst genre of anime'],\n",
    "['LMFAOOO evil ass laugh'],\n",
    "['that person gonna watch the movie like this']], columns=['texto_limpio'])\n",
    "mensajes_negativos_limpios = []\n",
    "for mensaje in mensajes_negativos.values:\n",
    "    mensajes_negativos_limpios.append(limpiar_texto(mensaje[0]))\n",
    "mensajes_negativos_limpios1 = pandas.DataFrame(mensajes_negativos_limpios,columns=['texto_limpio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomaremos como usuario positivo al futbolista @ErlingHaaland que es un delantero noruego del equipo inglés Manchester City que durante esta temporada ha ganado todo los títulos posibles y ha sido máximo goleador histórico de la liga inglesa, por lo que ha sido un año positivo para él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajes_positivos = pandas.DataFrame([\n",
    "['Honoured to win such an incredibly prestigious award  @theofficialfwa Thank you to all those who voted for me. Obviously, this wouldnt have been possible without the unbelievable support I have from everyone at @ManCity'],\n",
    "['Thanks to everyone for the support and love, these memories will last a lifetime!'],\n",
    "['Me and my baby'],\n",
    "['Always give your best. Always believe. It pays off. CMON CITY! '],\n",
    "['💯 Focus on tomorrow'],\n",
    "['Thank you! Busy morning 😅'],\n",
    "['Thank you everyone! 🙌🏻'],\n",
    "['Thank you 🙏🏻 and congratulations to back-to-back winner @samkerr1, amazing achievement!'],\n",
    "['Thank you 🙏🏻'],\n",
    "['It’s all in our hands... Can’t wait for the game next week! 🔜'],\n",
    "['Job done, looking forward to Tuesday! 👊🏻'],\n",
    "['Friend: how many league goals have you scored? Me:'],\n",
    "['@ErlingHaaland was Born to Goal. To celebrate his phenomenal @PremierLeague goalscoring record we created a unique phenomenon in the skies of Manchester. #Force9 #nikefc'],\n",
    "['A night to remember! 💙'],\n",
    "['35 Premier League goals 🤩 A big thank you to everyone for the support, nothing happens without you all, we dont stop here! 💙'],\n",
    "['We fight!'],\n",
    "['Cannot. Wait. 🔵 #mancity'],\n",
    "['Through to the final! 🔵 #mancity #FACup'],\n",
    "['Destiny is ALL 🔵 #mancity'],\n",
    "['Semis here we come! 💙 thanks to all our travelling fans for the support #mancity #UCL'],\n",
    "['Big week of results! 🔵 #mancity'],\n",
    "['Me and my magic potion 🥛💪🏻'],\n",
    "['Nothing but pure love for this competition! 🔵 #mancity #UCL'],\n",
    "['Wishing everyone celebrating a Happy Easter! 🐰 I hope you enjoy the special day with your loved ones! 🙏🏻'],\n",
    "['Back on the pitch! ⚡️🔵 #mancity'],\n",
    "['Good old days'],\n",
    "['Wishing everyone a happy, healthy & bright #ChineseNewYear! ✨'],\n",
    "['Positive spirit! 🔵 #mancity'],\n",
    "['What a team performance! Fans were unreal, thanks for being our 12th man 💙 #mancity'],\n",
    "['Very happy to get this achievement where it all started for me. 20 PL goals, and looking forward to many more! ☝🏻🤖🔵 #mancity'],],columns=['texto_limpio'])\n",
    "mensajes_positivos_limpios = []\n",
    "for mensaje in mensajes_positivos.values:\n",
    "    mensajes_positivos_limpios.append(limpiar_texto(mensaje[0]))\n",
    "mensajes_positivos_limpios1 = pandas.DataFrame(mensajes_positivos_limpios,columns=['texto_limpio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_negativas = clasif_kNN.predict(codificador_atributo.transform(mensajes_negativos_limpios1['texto_limpio']))\n",
    "array_negativo = codificador_objetivo.inverse_transform(predicciones_negativas)\n",
    "array_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_positivas = clasif_kNN.predict(codificador_atributo.transform(mensajes_positivos_limpios1['texto_limpio']))\n",
    "array_positivo = codificador_objetivo.inverse_transform(predicciones_positivas)\n",
    "array_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_negativos = dict(Counter(array_negativo))\n",
    "diccionario_positivos = dict(Counter(array_positivo))\n",
    "claves_negativas = list(diccionario_negativos.keys())\n",
    "claves_positivas = list(diccionario_positivos.keys())\n",
    "valores_negativos = list(diccionario_negativos.values())\n",
    "valores_positivos = list(diccionario_positivos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.pie(valores_negativos, labels=claves_negativas, startangle = 5, shadow = 'true')\n",
    "pyplot.title('Sentimiento de los tweets del Hater')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.pie(valores_positivos, labels=claves_positivas, startangle = 150, shadow = 'true')\n",
    "pyplot.title('Sentimientos de los tweets de persona positiva')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estos resultados los comentaremos en el documento, en el apartado resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
