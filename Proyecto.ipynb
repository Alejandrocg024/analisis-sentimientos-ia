{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install textblob\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para obtener un texto limpio a patir de un texto normal\n",
    "def limpiar_texto(texto):\n",
    "    # Eliminar menciones, hashtags, URLs y otros símbolos extraños\n",
    "    texto = re.sub(r'http\\S+', '', texto)  # eliminar URLs\n",
    "    texto = re.sub(r'#\\w+', '', texto)  # eliminar hashtags\n",
    "    texto = re.sub(r'@\\w+', '', texto)  # eliminar menciones\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)  # eliminar otros símbolos extraños\n",
    "    \n",
    "    # Convertir el texto a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(texto)\n",
    "    \n",
    "    # Eliminación de stop words y lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    palabras_limpias = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Unir las palabras limpias en una sola cadena de texto\n",
    "    texto_limpio = ' '.join(palabras_limpias)\n",
    "    \n",
    "    return texto_limpio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetado de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para etiquetar un texto ya limpio\n",
    "def etiquetar(texto):\n",
    "    # Crear un objeto TextBlob con el texto a analizar\n",
    "    blob = TextBlob(texto)\n",
    "    # Obtener el valor del análisis de sentimiento\n",
    "    sentimiento = blob.sentiment.polarity\n",
    "    # Asignar una etiqueta en función del valor del sentimiento\n",
    "    if sentimiento >= 0.7:\n",
    "        etiqueta = \"Muy feliz\"\n",
    "    elif sentimiento >= 0.3:\n",
    "        etiqueta = \"Contento\"\n",
    "    elif sentimiento >= -0.3:\n",
    "        etiqueta = \"Neutro\"\n",
    "    elif sentimiento >= -0.7:\n",
    "        etiqueta = \"Molesto\"\n",
    "    else:\n",
    "        etiqueta = \"Hater\"\n",
    "    return etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular el etiquetado según el número\n",
    "def calculo_etiqueta_valor(numero):\n",
    "    if numero == '4':\n",
    "        etiqueta = \"Muy feliz\"\n",
    "    elif numero == '3':\n",
    "        etiqueta = \"Contento\"\n",
    "    elif numero == '2':\n",
    "        etiqueta = \"Neutro\"\n",
    "    elif numero == '1':\n",
    "        etiqueta = \"Molesto\"\n",
    "    else:\n",
    "        etiqueta = \"Hater\"\n",
    "    return etiqueta\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir datos al csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_columna(input_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        rows = list(reader)\n",
    "        header = rows[0]\n",
    "        # Añadimos las 3 nuevas columnas\n",
    "        header.append('Texto limpio')\n",
    "        header.append('Valor propuesto')\n",
    "        header.append('Valor calculado')\n",
    "        for i in range(1, len(rows)):\n",
    "            # Usamos la columna en la cuál está el texto en bruto\n",
    "            valor_columna = rows[i][2]  \n",
    "            # Limpiamos el texto para que pueda ser analizado\n",
    "            texto_limpio = limpiar_texto(valor_columna)\n",
    "            # Lo etiquetamos\n",
    "            texto_etiquetado = etiquetar(texto_limpio)\n",
    "            # Calculamos el etiquetado que nos propuso el csv\n",
    "            valor_propuesto = calculo_etiqueta_valor(rows[i][1])\n",
    "            # Añadimos los nuevos valores\n",
    "            rows[i].append(texto_limpio) \n",
    "            rows[i].append(valor_propuesto)\n",
    "            rows[i].append(texto_etiquetado)  \n",
    "\n",
    "    # Guardar los cambios en un nuevo archivo CSV\n",
    "    output_file = 'DatosFinales.csv'\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregar_columna('DatosNuevos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDatos = pandas.read_csv('DatosFinales.csv', delimiter=';',encoding = 'latin-1', header=0,\n",
    "                       names=['id', 'valoración', 'mensaje', 'texto_limpio',\n",
    "                              'valor_propuesto', 'valor_calculado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5999, 6)\n"
     ]
    }
   ],
   "source": [
    "# Cantidad total de ejemplos\n",
    "print(csvDatos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de atributos y objetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributo = csvDatos['texto_limpio']  # selección de las columnas de atributos\n",
    "objetivo = csvDatos['valor_propuesto']  # selección de la columna objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0g milky bar left around 200ml coke' '1'\n",
      " '1 wank better none ensure mind blowing one' ...\n",
      " 'zombie mode today kid ill kept till 230am work 6am'\n",
      " 'zurich smelly bag anymore' nan]\n",
      "['Contento' 'Hater' 'Molesto' 'Muy feliz' 'Neutro']\n"
     ]
    }
   ],
   "source": [
    "# El codificador adecuado para tanto el atributo como el objetivo\n",
    "# es OrdinalEncoder, ya que trabaja con una lista o array\n",
    "# unidimensional de sus valores\n",
    "codificador_atributo = preprocessing.LabelEncoder()\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "atributo_codificado = codificador_atributo.fit_transform(atributo)\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)\n",
    "\n",
    "# Categorías detectadas por el codificador para cada atributo\n",
    "print(codificador_atributo.classes_)\n",
    "print(codificador_objetivo.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutro       0.654609\n",
      "Contento     0.180530\n",
      "Molesto      0.079013\n",
      "Muy feliz    0.068178\n",
      "Hater        0.017670\n",
      "Name: valor_propuesto, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pandas.Series(objetivo).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División para entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributo_entrenamiento, atributo_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributo_codificado, objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria, para que el muestreo sea reproducible,\n",
    "        # a pesar de ser aleatorio\n",
    "        random_state=12345,\n",
    "        # Tamaño del conjunto de prueba\n",
    "        test_size=.33,\n",
    "        # Estratificamos respecto a la distribución de valores en la variable objetivo\n",
    "        stratify=objetivo_codificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos de pruebas requeridos: 1979.67\n",
      "Filas del array de atributos de prueba: 1980\n",
      "Longitud del vector de objetivos de prueba: 1980\n",
      "Proporción de clases en el vector de objetivos de prueba:\n",
      "Neutro       0.654545\n",
      "Contento     0.180808\n",
      "Molesto      0.078788\n",
      "Muy feliz    0.068182\n",
      "Hater        0.017677\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos que el conjunto de prueba contiene el 33 % de los datos, en la misma proporción\n",
    "# con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de pruebas requeridos:', 5999 * .33)\n",
    "print('Filas del array de atributos de prueba:', atributo_prueba.shape[0])\n",
    "print('Longitud del vector de objetivos de prueba:', len(objetivo_prueba))\n",
    "print('Proporción de clases en el vector de objetivos de prueba:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_prueba)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos de entrenamiento requeridos: 4019.3300000000004\n",
      "Filas del array de atributos de entrenamiento: 4019\n",
      "Longitud del vector de objetivos de entrenamiento: 4019\n",
      "Proporción de clases en el vector de objetivos de entrenamiento:\n",
      "Neutro       0.654640\n",
      "Contento     0.180393\n",
      "Molesto      0.079124\n",
      "Muy feliz    0.068176\n",
      "Hater        0.017666\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos que el conjunto de entrenamiento contiene el resto de los datos, en la misma\n",
    "# proporción con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de entrenamiento requeridos:', 5999 * .67)\n",
    "print('Filas del array de atributos de entrenamiento:', atributo_entrenamiento.shape[0])\n",
    "print('Longitud del vector de objetivos de entrenamiento:', len(objetivo_entrenamiento))\n",
    "print('Proporción de clases en el vector de objetivos de entrenamiento:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_entrenamiento)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif_NB = naive_bayes.CategoricalNB(alpha=1.0)  # alpha es el parámetro de suavizado\n",
    "atributo_entrenamiento_2d = atributo_entrenamiento.reshape(-1, 1)\n",
    "clasif_NB.fit(atributo_entrenamiento_2d, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos para la clase Contento: 725.0\n",
      "Logaritmo de la probabilidad aprendida para la clase Contento: -1.7126167395945258\n",
      "Cantidad de ejemplos para la clase Hater: 71.0\n",
      "Logaritmo de la probabilidad aprendida para la clase Hater: -4.036108517407885\n",
      "Cantidad de ejemplos para la clase Molesto: 318.0\n",
      "Logaritmo de la probabilidad aprendida para la clase Molesto: -2.5367370116690235\n",
      "Cantidad de ejemplos para la clase Muy feliz: 274.0\n",
      "Logaritmo de la probabilidad aprendida para la clase Muy feliz: -2.68566028806113\n",
      "Cantidad de ejemplos para la clase Neutro: 2631.0\n",
      "Logaritmo de la probabilidad aprendida para la clase Neutro: -0.42366911340890745\n"
     ]
    }
   ],
   "source": [
    "for clase, cantidad_ejemplos_clase, log_probabilidad_clase in zip(\n",
    "    codificador_objetivo.classes_, clasif_NB.class_count_, clasif_NB.class_log_prior_):\n",
    "        print(f'Cantidad de ejemplos para la clase {clase}: {cantidad_ejemplos_clase}')\n",
    "        print(f'Logaritmo de la probabilidad aprendida para la clase {clase}: {log_probabilidad_clase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos para el atributo LabelEncoder():\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LabelEncoder' object has no attribute 'categories_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18012\\3753466835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Cantidad de ejemplos para el atributo {codificador_atributo}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m print(pandas.DataFrame(clasif_NB.category_count_[i],\n\u001b[1;32m----> 6\u001b[1;33m                       \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcodificador_atributo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                       index=codificador_objetivo.classes_))\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Logaritmos de las probabilidades aprendidas para el atributo {atributo}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LabelEncoder' object has no attribute 'categories_'"
     ]
    }
   ],
   "source": [
    "# for i, atributo in enumerate(codificador_atributos.feature_names_in_):\n",
    "i=0\n",
    "atributo = codificador_atributo\n",
    "print(f'Cantidad de ejemplos para el atributo {codificador_atributo}:')\n",
    "print(pandas.DataFrame(clasif_NB.category_count_[i],\n",
    "                      columns=codificador_atributo.categories_[i],\n",
    "                      index=codificador_objetivo.classes_))\n",
    "print(f'Logaritmos de las probabilidades aprendidas para el atributo {atributo}:')\n",
    "print(pandas.DataFrame(clasif_NB.feature_log_prob_[i],\n",
    "                      columns=codificador_atributo.categories_[i],\n",
    "                      index=codificador_objetivo.classes_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
