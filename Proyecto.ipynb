{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter SensIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar este proyecto haremos uso de los siguientes paquetes de Python:\n",
    "* _[_NLTK_](http://pandas.pydata.org/)_: herramienta para el an√°lisis de datos. Lo usaremos a la hora de \"limpiar\" el texto.\n",
    "* _[_Re_](https://docs.python.org/es/3/library/re.html)_: operaciones con expresiones regulares. Lo usaremos a la hora de \"limpiar\" el texto.\n",
    "* _[_TextBlob_](https://textblob.readthedocs.io/en/dev/)_: herramienta para procesar datos de texto. Lo usaremos para el etiquetado del texto.\n",
    "* _[_CSV_](https://docs.python.org/3/library/csv.html)_: herramienta para leer y escribir csv. Lo usaremos para tratar con csv, ya que tenemos familiaridad con √©ste.\n",
    "* _[_Pandas_](http://pandas.pydata.org/)_: herramienta para el an√°lisis de datos. Lo usaremos tambi√©n para trabajar con CSV.\n",
    "* _[_scikit-learn_](http://scikit-learn.org)_: herramienta que proporcioa un marco de trabajo para el aprendizaje autom√°tico. Lo usaremos para trabajar con nuesto modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los paquetes _NLTK_ y _TextBlob_ han de ser instalados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\pablo\\appdata\\roaming\\python\\python39\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, importamos todos los paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\pablo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Apartado 2: Eliminar palabras que no aportan informaci√≥n\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#Descargamos las ultimas versiones para que funcione correctamente\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Apartado 3: Etiquetado de datos\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Apartado 4\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Apartado 5\n",
    "#Apartado 6\n",
    "#Apartado 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodolog√≠a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 1. Recopilaci√≥n de datos\n",
    "\n",
    "Hemos recopilado 50.000 tweets que pueden tener un sentimiento positivo, negativo o neutro. Los hemos obtenido a trav√©s de [_Kaggle_](https://www.kaggle.com/datasets/kazanova/sentiment140) y los hemos almacenado en el fichero DatosRecopilados.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 2. Limpieza de texto\n",
    "\n",
    "Creamos una funci√≥n _limpiar_texto_ que, a partir de un tweet original, obtiene un texto limpio sin stop words, menciones, hastags, URLs y cualquier otro simbolo extra√±o utilizando t√©cnicas de lematizaci√≥n y tokenizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    # Eliminamos elementos que no nos sirven\n",
    "    texto = re.sub(r'http\\S+', \"\", texto)  # eliminamos URLs\n",
    "    texto = re.sub(r'#\\w+', \"\", texto)  # eliminamos hashtags\n",
    "    texto = re.sub(r'@\\w+', \"\", texto)  # eliminamos menciones\n",
    "    texto = re.sub(r'[^\\w\\s]', \"\", texto)  # eliminamos otros s√≠mbolos extra√±os\n",
    "    \n",
    "    # Convertimos el texto a min√∫sculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Tokenizaci√≥n\n",
    "    tokens = word_tokenize(texto)\n",
    "    \n",
    "    # Eliminamos stop words y lematizamos\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    palabras_limpias = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Palabras limpias a una sola cadena de texto\n",
    "    texto_limpio = ' '.join(palabras_limpias)\n",
    "    \n",
    "    return texto_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 3. Etiquetado de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una funci√≥n que sirva para poder etiquetar el texto que hemos limpiado previamente utilizando la libreria _TextBlob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar(texto):\n",
    "    # Creamos un objeto TextBlob con el texto a analizar\n",
    "    blob = TextBlob(texto)\n",
    "    # Valor del an√°lisis de sentimiento\n",
    "    sentimiento = blob.sentiment.polarity\n",
    "    # En funci√≥n del an√°lisis de sentimiento, etiquetamos\n",
    "    if sentimiento >= 0.7:\n",
    "        etiqueta = \"Muy feliz\"\n",
    "    elif sentimiento >= 0.2:\n",
    "        etiqueta = \"Contento\"\n",
    "    elif sentimiento >= -0.2:\n",
    "        etiqueta = \"Neutro\"\n",
    "    elif sentimiento >= -0.7:\n",
    "        etiqueta = \"Molesto\"\n",
    "    else:\n",
    "        etiqueta = \"Hater\"\n",
    "    return etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n crearemos una funci√≥n a la que le introduces el nombre del archivo csv que tenga los datos recopilados y limpios y etiqueta cada linea con su sentimiento correspondiente. La funci√≥n crear√° un csv con el nombre indicado que contiene dos columnas nuevas, una para cada texto limpio y otra para la etiqueta correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetado_datos(input_file, output_file):\n",
    "    #Leemos los datos delimitados por ;\n",
    "    reader = pandas.read_csv(input_file, delimiter=\";\")\n",
    "    #A√±adimos las 2 nuevas columnas\n",
    "    reader[\"Texto limpio\"] = \"\"\n",
    "    reader[\"Etiquetado\"] = \"\"\n",
    "    for i, row in reader.iterrows():\n",
    "        # Usamos la columna en la cu√°l est√° el texto en bruto\n",
    "        valor_columna = row[1]  \n",
    "        # Limpiamos el texto para que pueda ser analizado\n",
    "        texto_limpio = limpiar_texto(valor_columna)\n",
    "        # Lo etiquetamos\n",
    "        texto_etiquetado = etiquetar(texto_limpio)\n",
    "        # A√±adimos los nuevos valores a las correspondientes filas\n",
    "        reader.at[i, \"Texto limpio\"] = texto_limpio\n",
    "        reader.at[i, \"Etiquetado\"] = texto_etiquetado\n",
    "\n",
    "    # Guardamos los cambios en un nuevo archivo csv\n",
    "    reader.to_csv(output_file, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A√±adir datos al csv\n",
    "\n",
    "A continuaci√≥n, procesaremos todos los datos de prueba almcenados en \"DatosRecopilados.csv\" con las dos funciones realizadas y los almacenaremos en un archivo CSV llamado \"DatosFinales.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetado_datos('DatosRecopilados.csv', 'DatosFinales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 4. Validaci√≥n de la predicci√≥n realizada.\n",
    "\n",
    "A partir del csv generado en el apartado anterior \"DatosFinales.csv\" hemos creado el siguiente csv llamado \"DatosFinalesRevisados.csv\". As√≠, hemos creado un conjunto de datos etiquetados por un modelo ya existente y corregidos por un humano que usaremos como datos de entrenamiento y prueba en el desarrollo del modelo\n",
    "\n",
    "Por tanto, leemos nuestro csv corregido con las distintas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDatos = pandas.read_csv('DatosFinalesRevisados.csv', delimiter=';',encoding = 'utf-8', header=0,\n",
    "                       names=['id', 'mensaje', 'texto_limpio','valor_propuesto'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccion de atributos y objetivos\n",
    "\n",
    "A continuaci√≥n, seleccionamos los atributos y objetivos de nuestro modelo para, posteriormente codificarlos con las herramientas adecuadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributo = csvDatos['texto_limpio'].values.astype('U')   # selecci√≥n de las columnas de atributos\n",
    "objetivo = csvDatos['valor_propuesto']  # selecci√≥n de la columna objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos CountVectorizer para codificar el texto debido a que es el mejor \n",
    "# codificador a la hora de usar cadenas de texto puesto que no son etiquetas ni n√∫meros\n",
    "codificador_atributo = CountVectorizer()\n",
    "\n",
    "# Para codificar el objetivo usamos LabelEncoder debido a que solo puede tomar\n",
    "# 5 valores, es decir, etiquetas\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "\n",
    "atributo_codificado = codificador_atributo.fit_transform(atributo)\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el porcentaje de entradas que tienen las distintas etiquetas\n",
    "print(pandas.Series(objetivo).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 5. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributo_entrenamiento, atributo_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos √≠ndices para ambos\n",
    "        atributo_codificado, objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria, para que el muestreo sea reproducible,\n",
    "        # a pesar de ser aleatorio\n",
    "        random_state=12345,\n",
    "        # Tama√±o del conjunto de prueba\n",
    "        test_size=.33,\n",
    "        # Estratificamos respecto a la distribuci√≥n de valores en la variable objetivo\n",
    "        stratify=objetivo_codificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que el conjunto de prueba contiene el 33 % de los datos, en la misma proporci√≥n\n",
    "# con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de pruebas requeridos:', 50000 * .33)\n",
    "print('Filas del array de atributos de prueba:', atributo_prueba.shape[0])\n",
    "print('Longitud del vector de objetivos de prueba:', len(objetivo_prueba))\n",
    "print('Proporci√≥n de clases en el vector de objetivos de prueba:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_prueba)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que el conjunto de entrenamiento contiene el resto de los datos, en la misma\n",
    "# proporci√≥n con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de entrenamiento requeridos:', 50000 * .67)\n",
    "print('Filas del array de atributos de entrenamiento:', atributo_entrenamiento.shape[0])\n",
    "print('Longitud del vector de objetivos de entrenamiento:', len(objetivo_entrenamiento))\n",
    "print('Proporci√≥n de clases en el vector de objetivos de entrenamiento:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_entrenamiento)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_ejemplos = pandas.DataFrame([['im really sick fever'],\n",
    "                                    ['im happy family friends']], columns=['texto_limpio'])\n",
    "nuevos_ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_NB = naive_bayes.MultinomialNB(alpha=0.5)\n",
    "clasif_NB.fit(atributo_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasif_NB.predict(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))\n",
    "codificador_objetivo.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_NB.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba √Årboles de Decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_CART = tree.DecisionTreeClassifier(\n",
    "    max_depth=10,  # m√°xima profundidad del √°rbol\n",
    "    random_state=54321  # semilla aleatoria, para que el c√≥digo sea reproducible\n",
    ")\n",
    "clasif_CART.fit(atributo_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(50, 20))  # Anchura y altura del gr√°fico\n",
    "√°rbol = tree.plot_tree(clasif_CART,\n",
    "                       feature_names=codificador_atributo.get_feature_names_out(),\n",
    "                       class_names=codificador_objetivo.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasif_CART.predict(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))\n",
    "codificador_objetivo.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_CART.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN = neighbors.KNeighborsClassifier(\n",
    "    n_neighbors=5,  # N√∫mero de vecinos a considerar\n",
    "    metric='euclidean'  # Distancia eucl√≠dea como m√©trica\n",
    ")\n",
    "clasif_kNN.fit(atributo_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancias, vecinos = clasif_kNN.kneighbors(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecinos m√°s cercanos y distancia a ellos\n",
    "print(\"Ejemplo n√∫mero 1:\")\n",
    "print(nuevos_ejemplos.iloc[[0]])\n",
    "print()\n",
    "print(\"5 vecinos m√°s cercanos:\")\n",
    "print(pandas.DataFrame(codificador_atributo.inverse_transform(atributo_entrenamiento[vecinos[0]]),\n",
    "                       index=vecinos[0]).assign(\n",
    "    distancia=distancias[0],\n",
    "    clase=codificador_objetivo.inverse_transform(objetivo_entrenamiento[vecinos[0]])\n",
    "))\n",
    "\n",
    "print(\"\\n\\nEjemplo n√∫mero 2:\")\n",
    "print(nuevos_ejemplos.iloc[[1]])\n",
    "print()\n",
    "print(\"5 vecinos m√°s cercanos:\")\n",
    "print(pandas.DataFrame(codificador_atributo.inverse_transform(atributo_entrenamiento[vecinos[1]]),\n",
    "                       index=vecinos[1]).assign(\n",
    "    distancia=distancias[1],\n",
    "    clase=codificador_objetivo.inverse_transform(objetivo_entrenamiento[vecinos[1]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasif_kNN.predict(codificador_atributo.transform(nuevos_ejemplos['texto_limpio']))\n",
    "codificador_objetivo.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validaci√≥n cruzada de los m√©todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes\n",
    "#creo un diccionario vacio\n",
    "cv_scores_NB = {}\n",
    "for k in range(3, 21, 1):\n",
    "    k /= 10.0    #creo una instancia de modelo Naives Bayes para cada valor de suavizado (0.3-2.0)\n",
    "    clasif_NB = naive_bayes.MultinomialNB(alpha=k)\n",
    "    #guardo en cv_scores el resultado de cross_val_score que va hacer una validacion cruzada para cada suavizado\n",
    "    cv_scores = model_selection.cross_val_score(clasif_NB,\n",
    "                                                atributo_entrenamiento,\n",
    "                                                objetivo_entrenamiento,\n",
    "                                                #N√∫mero de pliegues en los que se dividen los datos para realizar la validaci√≥n\n",
    "                                                cv=10)\n",
    "    #lo guardo en el diccionario clave=suavizado, valor=media del resultado de la validacion cruzada para ese suavizado.\n",
    "    cv_scores_NB[k] = cv_scores.mean()\n",
    "\n",
    "# Muestro todas las puntuaciones\n",
    "print(cv_scores_NB)\n",
    "# Devuelvo el suavizado que obtiene una mejor puntuaci√≥n\n",
    "mejor_k_NB = max(cv_scores_NB, key=cv_scores_NB.get)\n",
    "print(f'Mejor suavizado: {mejor_k_NB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las 2 siguientes la estructura es la misma, por lo tanto no habr√° comentarios\n",
    "explicando qu√© hace cada paso, s√≥lo se mencionar√° aquello que sea distinto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en vez de hacerlo variando el suavizado, variamos la profundidad del √°rbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arboles de decisi√≥n\n",
    "#Tarda m√°s tiempo\n",
    "cv_scores_CART = {}\n",
    "for p in range(1,11):\n",
    "    clasif_CART = tree.DecisionTreeClassifier(max_depth=p)\n",
    "    cv_scores = model_selection.cross_val_score(clasif_CART,\n",
    "                                                atributo_entrenamiento,\n",
    "                                                objetivo_entrenamiento,\n",
    "                                                cv=10)\n",
    "    cv_scores_CART[p] = cv_scores.mean()\n",
    "print(cv_scores_CART)\n",
    "mejor_p_CART = max(cv_scores_CART, key=cv_scores_CART.get)\n",
    "print(f'Mejor profundidad: {mejor_p_CART}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora variamos el n√∫mero de vecinos que toma como referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN\n",
    "cv_scores_kNN = {}\n",
    "for k in range(1,11):\n",
    "    clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=k, metric='euclidean') \n",
    "    cv_scores = model_selection.cross_val_score(clasif_kNN,\n",
    "                                                atributo_entrenamiento,\n",
    "                                                objetivo_entrenamiento,\n",
    "                                                cv=10)\n",
    "    cv_scores_kNN[k] = cv_scores.mean()\n",
    "print(cv_scores_kNN)\n",
    "mejor_k_kNN = max(cv_scores_kNN, key=cv_scores_kNN.get)\n",
    "print(f'Mejor n√∫mero de vecinos: {mejor_k_kNN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 6. Predicci√≥n de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=mejor_k_kNN, metric='euclidean')\n",
    "clasif_kNN.fit(atributo_entrenamiento, objetivo_entrenamiento)\n",
    "clasif_kNN.score(atributo_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El acierto es del 67%. Es menor a lo que esper√°bamos, ya que hemos entrenado el modelo creemos que de la manera correcta con un conjunto de datos de 50.000 entradas. Sin embargo, creemos que uno de los principales factores por lo que no hemos alcanzado un mayor porcentaje es la infinidad de tweets distintos, es decir, la dificultad de que el texto limpio de 2 tweets coincidan. Esto nos ha llevado a que a la hora de calcular con TextBlob una entrada, el resultado no coincida con lo que los modelos basados en las dem√°s entradas nos ofrecen. Una vez obtenido este resultado hemos intentado realizar cambios que podr√≠an mejorar el porcentaje pero no hemos sido capaces de aumentar considerablemente el n√∫mero sin que aumente exponencialmente el tiempo de ejecuci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado 7. An√°lisis de tweets de personajes p√∫blicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomaremos como Hater al usuario @kirawontmiss que es un personaje p√∫blico con m√°s de 1 mill√≥n de seguidores que suele criticar noticias actuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajes_negativos = pandas.DataFrame([\n",
    "['i have a really bad feeling they‚Äôre gonna cast tom holland as link'],\n",
    "['please stop vaping we can‚Äôt see shit'],\n",
    "['why the FUCK are we even still paying bills?? the world is literally ending'],\n",
    "['YEAH THIS IS GETTING SO BAD.. WHAT THE FUCK DO U MEAN HAZARDOUS ??'],\n",
    "['LMFAOOO pixar deleted the tweet'],\n",
    "['yeah society is FINISHED.. mfs are really comparing wildfires'],\n",
    "['this gotta be the worst time to post this tweet LMAOO https://twitter.com/pixar/status/1666520608107298817'],\n",
    "['who the fuck owns Kick they are out here giving out NBA contracts'],\n",
    "['i had no problem with eminem until this horrible video dropped'],\n",
    "['SO THIS WASNT A JOKE???'],\n",
    "['FINALLY WE ARE FREE'],\n",
    "['nothing could‚Äôve prepared me for the ending'],\n",
    "['why the fuck don‚Äôt they jump over moving cars like this'],\n",
    "['LMAOO bro had the entire theater laughing'],\n",
    "['usually people hate when someone does this im surprised he got everyone laughing üò≠'],\n",
    "['do you know how unlucky you have to be for some shit like this to happen to you LMAOO'],\n",
    "['for $3499 that shit better let me see into the future wtf'],\n",
    "['why she dressed like a condom before you put it on LMAOOO'],\n",
    "['LMFAOOOOOO boruto didn‚Äôt influence shit'],\n",
    "['world war 2 is over.. y‚Äôall don‚Äôt have to eat like this anymore'],\n",
    "['he‚Äôs useless as fuck'],\n",
    "['WHAT THE FUCKKK THIS SHlT IS A MASTERPIECE'],\n",
    "['the way drake said embarrassing is exactly how i expected him to say it'],\n",
    "['why are you holding the drinks like this'],\n",
    "['Ai is gonna have y‚Äôall fucked up'],\n",
    "['IM NOT MAKING IT'],\n",
    "['alright its been 7 years who the fuck was behind those clowns costumes back in 2016'],\n",
    "['this is easily the worst genre of anime'],\n",
    "['LMFAOOO evil ass laugh'],\n",
    "['that person gonna watch the movie like this']], columns=['texto_limpio'])\n",
    "mensajes_negativos_limpios = []\n",
    "for mensaje in mensajes_negativos.values:\n",
    "    mensajes_negativos_limpios.append(limpiar_texto(mensaje[0]))\n",
    "mensajes_negativos_limpios1 = pandas.DataFrame(mensajes_negativos_limpios,columns=['texto_limpio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomaremos como usuario positivo al futbolista @ErlingHaaland que es un delantero noruego del equipo ingl√©s Manchester City que durante esta temporada ha ganado todo los t√≠tulos posibles y ha sido m√°ximo goleador hist√≥rico de la liga inglesa, por lo que ha sido un a√±o positivo para √©l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajes_positivos = pandas.DataFrame([\n",
    "['Honoured to win such an incredibly prestigious award  @theofficialfwa Thank you to all those who voted for me. Obviously, this wouldnt have been possible without the unbelievable support I have from everyone at @ManCity'],\n",
    "['Thanks to everyone for the support and love, these memories will last a lifetime!'],\n",
    "['Me and my baby'],\n",
    "['Always give your best. Always believe. It pays off. CMON CITY! '],\n",
    "['üíØ Focus on tomorrow'],\n",
    "['Thank you! Busy morning üòÖ'],\n",
    "['Thank you everyone! üôåüèª'],\n",
    "['Thank you üôèüèª and congratulations to back-to-back winner @samkerr1, amazing achievement!'],\n",
    "['Thank you üôèüèª'],\n",
    "['It‚Äôs all in our hands... Can‚Äôt wait for the game next week! üîú'],\n",
    "['Job done, looking forward to Tuesday! üëäüèª'],\n",
    "['Friend: how many league goals have you scored? Me:'],\n",
    "['@ErlingHaaland was Born to Goal. To celebrate his phenomenal @PremierLeague goalscoring record we created a unique phenomenon in the skies of Manchester. #Force9 #nikefc'],\n",
    "['A night to remember! üíô'],\n",
    "['35 Premier League goals ü§© A big thank you to everyone for the support, nothing happens without you all, we dont stop here! üíô'],\n",
    "['We fight!'],\n",
    "['Cannot. Wait. üîµ #mancity'],\n",
    "['Through to the final! üîµ #mancity #FACup'],\n",
    "['Destiny is ALL üîµ #mancity'],\n",
    "['Semis here we come! üíô thanks to all our travelling fans for the support #mancity #UCL'],\n",
    "['Big week of results! üîµ #mancity'],\n",
    "['Me and my magic potion ü•õüí™üèª'],\n",
    "['Nothing but pure love for this competition! üîµ #mancity #UCL'],\n",
    "['Wishing everyone celebrating a Happy Easter! üê∞ I hope you enjoy the special day with your loved ones! üôèüèª'],\n",
    "['Back on the pitch! ‚ö°Ô∏èüîµ #mancity'],\n",
    "['Good old days'],\n",
    "['Wishing everyone a happy, healthy & bright #ChineseNewYear! ‚ú®'],\n",
    "['Positive spirit! üîµ #mancity'],\n",
    "['What a team performance! Fans were unreal, thanks for being our 12th man üíô #mancity'],\n",
    "['Very happy to get this achievement where it all started for me. 20 PL goals, and looking forward to many more! ‚òùüèªü§ñüîµ #mancity'],],columns=['texto_limpio'])\n",
    "mensajes_positivos_limpios = []\n",
    "for mensaje in mensajes_positivos.values:\n",
    "    mensajes_positivos_limpios.append(limpiar_texto(mensaje[0]))\n",
    "mensajes_positivos_limpios1 = pandas.DataFrame(mensajes_positivos_limpios,columns=['texto_limpio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_negativas = clasif_kNN.predict(codificador_atributo.transform(mensajes_negativos_limpios1['texto_limpio']))\n",
    "array_negativo = codificador_objetivo.inverse_transform(predicciones_negativas)\n",
    "array_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_positivas = clasif_kNN.predict(codificador_atributo.transform(mensajes_positivos_limpios1['texto_limpio']))\n",
    "array_positivo = codificador_objetivo.inverse_transform(predicciones_positivas)\n",
    "array_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_negativos = dict(Counter(array_negativo))\n",
    "diccionario_positivos = dict(Counter(array_positivo))\n",
    "claves_negativas = list(diccionario_negativos.keys())\n",
    "claves_positivas = list(diccionario_positivos.keys())\n",
    "valores_negativos = list(diccionario_negativos.values())\n",
    "valores_positivos = list(diccionario_positivos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.pie(valores_negativos, labels=claves_negativas, startangle = 5, shadow = 'true')\n",
    "pyplot.title('Sentimiento de los tweets del Hater')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.pie(valores_positivos, labels=claves_positivas, startangle = 150, shadow = 'true')\n",
    "pyplot.title('Sentimientos de los tweets de persona positiva')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estos resultados los comentaremos en el documento, en el apartado resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
